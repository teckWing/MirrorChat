{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEwXErrTbOQg",
        "outputId": "181e8901-a4fe-4603-f8fc-2ec7a938b84c"
      },
      "outputs": [],
      "source": [
        "!pip install -q gpt-2-simple\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HtYzU2d9cg4a"
      },
      "outputs": [],
      "source": [
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files\n",
        "import random\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLuaYIs3c0FY",
        "outputId": "4972579e-48bf-468a-9004-157705c11676"
      },
      "outputs": [],
      "source": [
        "# options : 124M, 355M, 774M, 1558M\n",
        "gpt2.download_gpt2(model_name=\"124M\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dv1Jhhn4bWJ7",
        "outputId": "ece8fd99-bd07-461d-e310-3dfb34c8915d"
      },
      "outputs": [],
      "source": [
        "# if you stop this chunck, to restart the training you need to restart the colab vm\n",
        "file_name = \"data.txt\" # File name of dataset\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(\n",
        "            sess,\n",
        "            dataset=file_name,\n",
        "            model_name='124M', # Model you have already downloaded\n",
        "            steps=-1, # -1 will do unlimited. Enter number of iterations otherwise\n",
        "            restore_from='fresh', # Set to fresh to start training from the base GPT-2, or set to latest to restart training from an existing checkpoint.\n",
        "            run_name='mirrorChat', # The name to pull or create a checkpoint under\n",
        "            print_every=50, # Print iterations every X numebr\n",
        "            sample_every=150, # Generate a text sample ever X number of iter.\n",
        "            save_every=500, # Save a snapshot every X number of iter.\n",
        "            learning_rate=0.0001, # Lower to 0.00001 if you are not getting massive changes in results\n",
        "            batch_size=1, # Keep at 1 or 2, will use up more memory if you raise this\n",
        "            overwrite= False # Set to True if you want to continue finetuning an existing model (w/ restore_from='latest') without creating duplicate copies.\n",
        "            )\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# if you are training on colab and at the end you will download checkpoint\n",
        "directory_to_compress = '/content/checkpoint'\n",
        "output_zip_file = '/content/checkpoint'\n",
        "shutil.make_archive(output_zip_file , 'zip', directory_to_compress)\n",
        "files.download(output_zip_file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
